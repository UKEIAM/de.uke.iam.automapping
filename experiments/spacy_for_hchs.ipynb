{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length 1033 and length of unique data 959\n"
     ]
    }
   ],
   "source": [
    "HCHS_data=pd.read_excel('/workspaces/de.uke.iam.automapping/experiments/VM_Soarian_HCHS_20210422.xlsx')\n",
    "print(f\"Data length {len(HCHS_data['Langname']) } and length of unique data {len(HCHS_data['Langname'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCHS_data['Langname']=HCHS_data['Langname'].replace([' ', ''], np.nan)\n",
    "HCHS_Langname=HCHS_data['Langname'].str.strip()\n",
    "HCHS_Langname=HCHS_Langname.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('de_core_news_lg') #load model with german language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existence(data):\n",
    "    \"\"\"Get words which exist and non exist in spaCy german model\"\"\"\n",
    "    existing_words=[] \n",
    "    non_existing_words=[]\n",
    "    for s in data:\n",
    "        doc=nlp(s)\n",
    "        for token in doc:\n",
    "            if ((token.pos_!='SPACE') & (token.pos_!='CCONJ') & (token.pos_!='PUNCT') & (token.pos_!='NUM')) and not token.is_stop and not token.is_punct: #drop punctuation, number, spaces, stop words\n",
    "                if token.has_vector is True:\n",
    "                    existing_words.append(str(token))\n",
    "                else:\n",
    "                    non_existing_words.append(str(token))\n",
    "    return existing_words, non_existing_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_words, non_existing_words=get_existence(HCHS_Langname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_tokens: 2937, where 2315 words we found and 622 words we didn't find\n",
      "percent of existing words: 78.8%\n",
      "Most common words from non existing ones: [('Echogenität', 22), ('extracraniell', 20), ('intracraniell', 20), ('T1_nativ', 17), ('T1_postKM', 17), ('L-G-E', 16), ('Stenosegrad', 15), ('abhängigem', 15), ('Nebenbefund', 14), ('Diffusionsrestriktion', 12)]\n",
      "Most common words from existing ones: [('Segment', 96), ('links', 69), ('rechts', 67), ('Stenose', 64), ('Diameter', 55), ('Mapping', 52), ('Zeile', 37), ('PD', 32), ('vorhanden', 31), ('|', 30)]\n"
     ]
    }
   ],
   "source": [
    "dict_existing_words={}\n",
    "dict_non_existing_words={}\n",
    "dict_existing_words=Counter(existing_words)\n",
    "dict_non_existing_words=Counter(non_existing_words)\n",
    "\n",
    "print(f\"number_of_tokens: {len(existing_words)+len(non_existing_words)}, where {len(existing_words)} words we found and {len(non_existing_words)} words we didn't find\")\n",
    "print(f\"percent of existing words: {len(existing_words)/(len(existing_words)+len(non_existing_words)):.1%}\")\n",
    "print(f\"Most common words from non existing ones: {dict_non_existing_words.most_common(10)}\")\n",
    "print(f\"Most common words from existing ones: {dict_existing_words.most_common(10)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing around spaCy and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=nlp.pipe(HCHS_Langname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tokens_plus_meta(doc:spacy.tokens.doc.Doc):\n",
    "    \"\"\"Extract tokens and metadata from individual spaCy doc.\"\"\"\n",
    "    return [\n",
    "        (i.text, i.i, i.lemma_, i.ent_type_, i.tag_, \n",
    "         i.dep_, i.pos_, i.is_stop, i.is_alpha, \n",
    "         i.is_digit, i.is_punct, i.has_vector) for i in doc\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_tokens(docs):\n",
    "    \"\"\"Extract tokens and metadata from list of spaCy docs.\"\"\"\n",
    "    \n",
    "    cols = [\n",
    "        \"doc_id\", \"token\", \"token_order\", \"lemma\", \n",
    "        \"ent_type\", \"tag\", \"dep\", \"pos\", \"is_stop\", \n",
    "        \"is_alpha\", \"is_digit\", \"is_punct\", \"has_vector\"\n",
    "    ]\n",
    "    \n",
    "    meta_df = []\n",
    "    for ix, doc in enumerate(docs):\n",
    "        meta = extract_tokens_plus_meta(doc)\n",
    "        meta = pd.DataFrame(meta)\n",
    "        #print(meta)\n",
    "        meta.columns = cols[1:]\n",
    "        meta = meta.assign(doc_id = ix).loc[:, cols]\n",
    "        meta_df.append(meta)\n",
    "        \n",
    "    return pd.concat(meta_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_order</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>pos</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_digit</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>has_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Liegt</td>\n",
       "      <td>0</td>\n",
       "      <td>Liegt</td>\n",
       "      <td></td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>bei</td>\n",
       "      <td>1</td>\n",
       "      <td>bei</td>\n",
       "      <td></td>\n",
       "      <td>APPR</td>\n",
       "      <td>mo</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ihnen</td>\n",
       "      <td>2</td>\n",
       "      <td>ich</td>\n",
       "      <td></td>\n",
       "      <td>PPER</td>\n",
       "      <td>nk</td>\n",
       "      <td>PRON</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>eine</td>\n",
       "      <td>3</td>\n",
       "      <td>einen</td>\n",
       "      <td></td>\n",
       "      <td>ART</td>\n",
       "      <td>nk</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>vom</td>\n",
       "      <td>4</td>\n",
       "      <td>vom</td>\n",
       "      <td></td>\n",
       "      <td>APPRART</td>\n",
       "      <td>sbp</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  token  token_order  lemma ent_type      tag   dep   pos  is_stop  \\\n",
       "0       0  Liegt            0  Liegt             VVFIN  ROOT  VERB    False   \n",
       "1       0    bei            1    bei              APPR    mo   ADP     True   \n",
       "2       0  Ihnen            2    ich              PPER    nk  PRON     True   \n",
       "3       0   eine            3  einen               ART    nk   DET     True   \n",
       "4       0    vom            4    vom           APPRART   sbp   ADP     True   \n",
       "\n",
       "   is_alpha  is_digit  is_punct  has_vector  \n",
       "0      True     False     False        True  \n",
       "1      True     False     False        True  \n",
       "2      True     False     False        True  \n",
       "3      True     False     False        True  \n",
       "4      True     False     False        True  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=tidy_tokens(docs)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_order</th>\n",
       "      <th>lemma</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>pos</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_digit</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>has_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Medikamentenerfassung</td>\n",
       "      <td>2</td>\n",
       "      <td>Medikamentenerfassung</td>\n",
       "      <td></td>\n",
       "      <td>NN</td>\n",
       "      <td>sb</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>Berichtetes</td>\n",
       "      <td>0</td>\n",
       "      <td>Berichtetes</td>\n",
       "      <td>PER</td>\n",
       "      <td>NE</td>\n",
       "      <td>ag</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>Gemessener</td>\n",
       "      <td>0</td>\n",
       "      <td>Gemessener</td>\n",
       "      <td>PER</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>nk</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Gemessener</td>\n",
       "      <td>0</td>\n",
       "      <td>Gemessener</td>\n",
       "      <td>PER</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>nk</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>HB-Schnelltest</td>\n",
       "      <td>0</td>\n",
       "      <td>HB-Schnelltest</td>\n",
       "      <td></td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>HB-Wert</td>\n",
       "      <td>0</td>\n",
       "      <td>HB-Wert</td>\n",
       "      <td></td>\n",
       "      <td>VVPP</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1xEDTA</td>\n",
       "      <td>3</td>\n",
       "      <td>1xEDTA</td>\n",
       "      <td></td>\n",
       "      <td>ADV</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ADV</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Monovette</td>\n",
       "      <td>4</td>\n",
       "      <td>Monovette</td>\n",
       "      <td></td>\n",
       "      <td>NN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>1xHeparin</td>\n",
       "      <td>3</td>\n",
       "      <td>1xHeparin</td>\n",
       "      <td></td>\n",
       "      <td>NN</td>\n",
       "      <td>mo</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>Monovette</td>\n",
       "      <td>4</td>\n",
       "      <td>Monovette</td>\n",
       "      <td>PER</td>\n",
       "      <td>NE</td>\n",
       "      <td>pnc</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                  token  token_order                  lemma ent_type  \\\n",
       "2      13  Medikamentenerfassung            2  Medikamentenerfassung            \n",
       "0      15            Berichtetes            0            Berichtetes      PER   \n",
       "0      16             Gemessener            0             Gemessener      PER   \n",
       "0      17             Gemessener            0             Gemessener      PER   \n",
       "0      19         HB-Schnelltest            0         HB-Schnelltest            \n",
       "0      20                HB-Wert            0                HB-Wert            \n",
       "3      22                 1xEDTA            3                 1xEDTA            \n",
       "4      22              Monovette            4              Monovette            \n",
       "3      23              1xHeparin            3              1xHeparin            \n",
       "4      23              Monovette            4              Monovette      PER   \n",
       "\n",
       "    tag   dep    pos  is_stop  is_alpha  is_digit  is_punct  has_vector  \n",
       "2    NN    sb   NOUN    False      True     False     False       False  \n",
       "0    NE    ag    ADJ    False      True     False     False       False  \n",
       "0  ADJA    nk    ADJ    False      True     False     False       False  \n",
       "0  ADJA    nk    ADJ    False      True     False     False       False  \n",
       "0    NE  ROOT  PROPN    False     False     False     False       False  \n",
       "0  VVPP  ROOT   VERB    False     False     False     False       False  \n",
       "3   ADV  ROOT    ADV    False     False     False     False       False  \n",
       "4    NN  ROOT    ADJ    False      True     False     False       False  \n",
       "3    NN    mo   NOUN    False     False     False     False       False  \n",
       "4    NE   pnc  PROPN    False      True     False     False       False  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['has_vector']==False].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
